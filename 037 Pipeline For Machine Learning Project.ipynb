{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Data importing and processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# The data\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# For Scaling the data in range of 0-1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# For reducing the dimentionality of the data\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# For splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Creating a Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# For creating a model1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# For creating a model2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# For creating a model3\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# For evaluating our performance\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.data\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines Creation\n",
    "#### 1. Data Preprocessing by using Standard Scaler\n",
    "#### 2. Reduce Dimension using PCA\n",
    "#### 3. Apply  Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline([('MinMaxscaler1', MinMaxScaler()), \n",
    "                       ('PCA1', PCA(n_components=10)), \n",
    "                       ('lr_classification', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_rf = Pipeline([('MinMaxscaler2', MinMaxScaler()), \n",
    "                       ('PCA2', PCA(n_components=10)), \n",
    "                       ('rf_classification', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_xg = Pipeline([('MinMaxscaler3', MinMaxScaler()), \n",
    "                       ('PCA3', PCA(n_components=10)), \n",
    "                       ('xg_classification', XGBClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making List of Pipeline\n",
    "\n",
    "mypipelines = [pipeline_lr, pipeline_rf, pipeline_xg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating variables to store values\n",
    "\n",
    "best_accuracy=0.0\n",
    "best_classifier=0\n",
    "best_pipeline=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "\n",
    "pipe_dict = {0: 'Logistic Regression', 1: 'Random Forest', 2: 'XGB Classifier'}\n",
    "\n",
    "# Fit the pipelines\n",
    "\n",
    "for pipe in mypipelines:\n",
    "    pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy : 0.956140350877193\n",
      "Random Forest Test Accuracy : 0.9473684210526315\n",
      "XGB Classifier Test Accuracy : 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(mypipelines):\n",
    "    print(f'{pipe_dict[i]} Test Accuracy : {model.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification With Best Accuracy: XGB Classifier\n"
     ]
    }
   ],
   "source": [
    "# Choosing the best Model for the given data\n",
    "\n",
    "for i, model in enumerate(mypipelines):\n",
    "    if model.score(X_test, y_test) > best_accuracy:\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        \n",
    "        best_pipeline = model\n",
    "        \n",
    "        best_classifier = i\n",
    "        \n",
    "print(f\"Classification With Best Accuracy: {pipe_dict[best_classifier]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "_____________________________________________________________________________________________________________________________\n",
    "\n",
    "# Hyperparameter Tuning With Grid SearchCV Using Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "my_pip = Pipeline([(\"classification\", XGBClassifier())])\n",
    "\n",
    "# Create dictionary with candidate learning algorithms and their hyperparameters\n",
    "\n",
    "grid_parameters = [{\"classification\": [LogisticRegression()], \n",
    "                    \"classification__penalty\": ['l2','l1'], \n",
    "                    \"classification__C\": np.logspace(0,4,10)}, \n",
    "                  \n",
    "                   {\"classification\": [RandomForestClassifier()], \n",
    "                    \"classification__n_estimators\": [10,100,1000], \n",
    "                    \"classification__max_depth\": [5,10,15,20,25,50,100]}, \n",
    "                   \n",
    "                   {\"classification\": [XGBClassifier()], \n",
    "                    \"classification__penalty\": ['l2','l1'], \n",
    "                    \"classification__booster\": ['gbtree', 'gblinear']}]\n",
    "\n",
    "# create a gridsearch of the pipeline, the fit the best model\n",
    "\n",
    "gridsearch = GridSearchCV(my_pip, grid_parameters, cv=5, verbose=0,n_jobs=-1) # Fit grid search\n",
    "best_model = gridsearch.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('classification', RandomForestClassifier(max_depth=10))])\n",
      "The mean accuracy of the model is: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "print(best_model.best_estimator_)\n",
    "print(\"The mean accuracy of the model is:\",best_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "_____________________________________________________________________________________________________________________________\n",
    "\n",
    "# Make_pipelines in Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9385964912280702"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe = make_pipeline((RandomForestClassifier()))\n",
    "\n",
    "# Create dictionary with candidate learning algorithms and their hyperparameters\n",
    "\n",
    "grid_param = [\n",
    "                {\"randomforestclassifier\": [RandomForestClassifier()],\n",
    "                 \"randomforestclassifier__n_estimators\": [10, 100, 1000],\n",
    "                 \"randomforestclassifier__max_depth\":[5,8,15,25,30,None],\n",
    "                 \"randomforestclassifier__min_samples_leaf\":[1,2,5,10,15,100],\n",
    "                 \"randomforestclassifier__max_leaf_nodes\": [2, 5,10]}]\n",
    "\n",
    "# create a gridsearch of the pipeline, the fit the best model\n",
    "\n",
    "gridsearch = GridSearchCV(pipe, grid_param, cv=5, verbose=0,n_jobs=-1) # Fit grid search\n",
    "best_model = gridsearch.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "best_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
